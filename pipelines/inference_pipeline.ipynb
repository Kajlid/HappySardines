{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a6d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error\n",
    ")\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd3c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-07 10:53:48,607 INFO: Initializing external client\n",
      "2026-01-07 10:53:48,607 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-07 10:53:50,127 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1271989\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "project_name = os.getenv(\"HOPSWORKS_PROJECT\")\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "test_start_string = os.getenv(\"TEST_START_DATE\")\n",
    "test_start_date = pd.to_datetime(test_start_string).date()\n",
    "\n",
    "project = hopsworks.login(project=project_name, api_key_value=api_key)\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "model_name = \"occupancy_xgboost_model_new\"\n",
    "model_version = 2\n",
    "today = pd.Timestamp.utcnow().floor(\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1346529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features used for training\n",
    "VEHICLE_FEATURES = [\n",
    "    \"trip_id\",\n",
    "    \"vehicle_id\",\n",
    "    \"max_speed\",\n",
    "    \"n_positions\",\n",
    "    \"lat_mean\",\n",
    "    \"lon_mean\",\n",
    "    \"hour\",\n",
    "    \"day_of_week\",\n",
    "]\n",
    "\n",
    "WEATHER_FEATURES = [\n",
    "    \"temperature_2m\",\n",
    "    \"precipitation\",\n",
    "    \"cloud_cover\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"snowfall\",\n",
    "    \"rain\"\n",
    "]\n",
    "\n",
    "HOLIDAY_FEATURES = [\n",
    "    \"is_work_free\",\n",
    "    \"is_red_day\",\n",
    "    \"is_day_before_holiday\",\n",
    "]\n",
    "\n",
    "# Target variable\n",
    "TARGET = \"occupancy_mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2ab20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.97s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.72s) \n"
     ]
    }
   ],
   "source": [
    "vehicle_trip_agg_fg = fs.get_feature_group(\n",
    "    name=\"vehicle_trip_agg_fg\",\n",
    "    version=2\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\"weather_hourly_fg\", version=1)\n",
    "weather_df = weather_fg.read()\n",
    "weather_df[\"datetime_hour\"] = pd.to_datetime(weather_df[\"timestamp\"]).dt.floor(\"H\")\n",
    "\n",
    "holiday_fg = fs.get_feature_group(\"swedish_holidays_fg\", version=1)\n",
    "holiday_df = holiday_fg.read()\n",
    "holiday_df[\"datetime_hour\"] = pd.to_datetime(holiday_df[\"date\"]).dt.floor(\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5de51fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1488\n",
      "730\n"
     ]
    }
   ],
   "source": [
    "print(len(weather_df))\n",
    "print(len(holiday_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219b2de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (114.67s) \n",
      "6442370\n",
      "6442370\n",
      "6442370\n"
     ]
    }
   ],
   "source": [
    "monitor_df = vehicle_trip_agg_fg.read()\n",
    "print(len(monitor_df))\n",
    "monitor_df[\"window_start\"] = pd.to_datetime(monitor_df[\"window_start\"])\n",
    "monitor_df[\"datetime_hour\"] = monitor_df[\"window_start\"].dt.floor(\"H\")\n",
    "monitor_df[\"_date\"] = monitor_df[\"window_start\"].dt.date\n",
    "\n",
    "# Merge weather by datetime_hour\n",
    "monitor_df = monitor_df.merge(\n",
    "    weather_df[[\"datetime_hour\"] + WEATHER_FEATURES],\n",
    "    on=\"datetime_hour\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(len(monitor_df))\n",
    "\n",
    "# Merge holidays by day\n",
    "holiday_df[\"date\"] = pd.to_datetime(holiday_df[\"date\"]).dt.date\n",
    "monitor_df = monitor_df.merge(\n",
    "    holiday_df[[\"date\"] + HOLIDAY_FEATURES],\n",
    "    left_on=\"_date\",\n",
    "    right_on=\"date\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(len(monitor_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "407a0865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-07 10:57:01,077 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e239b3449c264bbc8df273fcc2cbe215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/1747261 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d13b75ef99648d1a45b405045962a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/43482 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "# Download the model from the model registry\n",
    "\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "retrieved_model = mr.get_model(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    ")\n",
    "\n",
    "fv = retrieved_model.get_feature_view()\n",
    "\n",
    "# Download the saved model artifacts to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd193201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupancy_fv\n"
     ]
    }
   ],
   "source": [
    "print(fv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb7cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.load_model(Path(saved_model_dir) / \"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a658fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.19s) \n"
     ]
    }
   ],
   "source": [
    "static_trip_info_fg = fs.get_feature_group(\n",
    "    name=\"static_trip_info_fg\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "static_df = static_trip_info_fg.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30b69130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linköping bus station coordinates as default monitoring point: https://traveling.com/sv/buss/station/linkoeping-busstation \n",
    "DEFAULT_LAT = 58.419274\n",
    "DEFAULT_LON = 15.619256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5bca3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "OPENMETEO_FORECAST_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "WEATHER_VARIABLES = [\n",
    "    \"temperature_2m\",\n",
    "    \"precipitation\",\n",
    "    \"cloud_cover\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"rain\",\n",
    "    \"snowfall\"\n",
    "]\n",
    "\n",
    "MAX_RETRIES = 5\n",
    "INITIAL_DELAY = 1  # seconds\n",
    "\n",
    "def get_weather_for_prediction(lat: float, lon: float, forecast_days: int) -> dict:\n",
    "    \"\"\"\n",
    "    Get weather forecast for a specific location and time with exponential backoff.\n",
    "\n",
    "    Args:\n",
    "        lat: Latitude\n",
    "        lon: Longitude\n",
    "        target_datetime: Target datetime for prediction\n",
    "\n",
    "    Returns:\n",
    "        Dict with weather features for the model\n",
    "    \"\"\"\n",
    "    # now = datetime.now()\n",
    "    # days_ahead = (target_datetime.date() - now.date()).days\n",
    "\n",
    "    # if days_ahead > 16:\n",
    "    #     print(f\"Warning: Date too far in future, using default weather\")\n",
    "    #     return _default_weather()\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"hourly\": \",\".join(WEATHER_VARIABLES),\n",
    "        \"timezone\": \"Europe/Stockholm\",\n",
    "        \"forecast_days\": forecast_days,\n",
    "    }\n",
    "\n",
    "    delay = INITIAL_DELAY\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            response = requests.get(OPENMETEO_FORECAST_URL, params=params, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                hourly = data.get(\"hourly\", {})\n",
    "                if not hourly:\n",
    "                    return _default_weather()\n",
    "\n",
    "                # Match target hour\n",
    "                times = hourly.get(\"time\", [])\n",
    "                try:\n",
    "                    idx = times.index(target_str)\n",
    "                except ValueError:\n",
    "                    target_hour = target_datetime.hour\n",
    "                    target_date = target_datetime.strftime(\"%Y-%m-%d\")\n",
    "                    for i, t in enumerate(times):\n",
    "                        if t.startswith(target_date) and f\"T{target_hour:02d}:\" in t:\n",
    "                            idx = i\n",
    "                            break\n",
    "                    else:\n",
    "                        print(f\"Could not find matching hour for {target_datetime}\")\n",
    "                        return _default_weather()\n",
    "\n",
    "                return {\n",
    "                    \"temperature_2m\": hourly.get(\"temperature_2m\", [None])[idx] or 10.0,\n",
    "                    \"precipitation\": hourly.get(\"precipitation\", [None])[idx] or 0.0,\n",
    "                    \"cloud_cover\": hourly.get(\"cloud_cover\", [None])[idx] or 50.0,\n",
    "                    \"wind_speed_10m\": hourly.get(\"wind_speed_10m\", [None])[idx] or 5.0,\n",
    "                    \"rain\": hourly.get(\"rain\", [None])[idx] or 0.0,\n",
    "                    \"snowfall\": hourly.get(\"snowfall\", [None])[idx] or 0.0,\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                print(f\"Weather API returned status {response.status_code}. Retrying in {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # exponential backoff\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Weather API request failed: {e}. Retrying in {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "            delay *= 2\n",
    "\n",
    "    print(f\"Max retries reached for {target_datetime}, returning default weather\")\n",
    "    return _default_weather()\n",
    "\n",
    "\n",
    "def fetch_weather_all_hours(lat, lon, forecast_days=7):\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"hourly\": \",\".join(WEATHER_VARIABLES),\n",
    "        \"timezone\": \"Europe/Stockholm\",\n",
    "        \"forecast_days\": forecast_days\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(OPENMETEO_FORECAST_URL, params=params, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json().get(\"hourly\", {})\n",
    "        return data\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Weather API request failed: {e}, returning defaults\")\n",
    "        # Build default hourly data for each variable\n",
    "        return {var: [0.0]*(forecast_days*24) for var in WEATHER_VARIABLES} | {\"time\": []}\n",
    "\n",
    "\n",
    "def _default_weather() -> dict:\n",
    "    \"\"\"Return default weather values.\"\"\"\n",
    "    return {\n",
    "        \"temperature_2m\": 10.0,\n",
    "        \"precipitation\": 0.0,\n",
    "        \"cloud_cover\": 50.0,\n",
    "        \"wind_speed_10m\": 5.0,\n",
    "        \"rain\": 0.0,\n",
    "        \"snowfall\": 0.0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c8b2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Svenska Dagar API\n",
    "SVENSKA_DAGAR_API_URL = \"https://sholiday.faboul.se/dagar/v2.1\"\n",
    "\n",
    "\n",
    "def get_holiday_features(target_datetime: datetime) -> dict:\n",
    "    \"\"\"\n",
    "    Get holiday features for a specific date.\n",
    "\n",
    "    Args:\n",
    "        target_datetime: Target datetime\n",
    "\n",
    "    Returns:\n",
    "        Dict with holiday features for the model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date = target_datetime.date()\n",
    "        url = f\"{SVENSKA_DAGAR_API_URL}/{date.year}/{date.month:02d}/{date.day:02d}\"\n",
    "\n",
    "        response = requests.get(url, timeout=30)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Holiday API error: {response.status_code}\")\n",
    "            return _default_holidays(target_datetime)\n",
    "\n",
    "        data = response.json()\n",
    "        days = data.get(\"dagar\", [])\n",
    "\n",
    "        if not days:\n",
    "            return _default_holidays(target_datetime)\n",
    "\n",
    "        day = days[0]\n",
    "\n",
    "        return {\n",
    "            \"is_work_free\": day.get(\"arbetsfri dag\") == \"Ja\",\n",
    "            \"is_red_day\": day.get(\"röd dag\") == \"Ja\",\n",
    "            \"is_day_before_holiday\": day.get(\"dag före arbetsfri helgdag\") == \"Ja\",\n",
    "            \"holiday_name\": day.get(\"helgdag\"),\n",
    "            \"day_of_week\": int(day.get(\"dag i vecka\", target_datetime.weekday() + 1)) - 1,  # Convert to 0-indexed\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching holiday data: {e}\")\n",
    "        return _default_holidays(target_datetime)\n",
    "\n",
    "\n",
    "def _default_holidays(target_datetime: datetime) -> dict:\n",
    "    \"\"\"Return default holiday values based on day of week.\"\"\"\n",
    "    day_of_week = target_datetime.weekday()\n",
    "\n",
    "    # Weekends are typically work-free\n",
    "    is_weekend = day_of_week >= 5\n",
    "\n",
    "    return {\n",
    "        \"is_work_free\": is_weekend,\n",
    "        \"is_red_day\": day_of_week == 6,  # Sundays are red days\n",
    "        \"is_day_before_holiday\": False,\n",
    "        \"holiday_name\": None,\n",
    "        \"day_of_week\": day_of_week,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f0d0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_days = 7\n",
    "start_date = today\n",
    "hours = list(range(5, 24))          # hours relevant for predicting occupancy\n",
    "\n",
    "FEATURE_ORDER = [\n",
    "    \"trip_id\",\n",
    "    \"vehicle_id\",\n",
    "    \"max_speed\",\n",
    "    \"n_positions\",\n",
    "    \"lat_mean\",\n",
    "    \"lon_mean\",\n",
    "    \"hour\",\n",
    "    \"day_of_week\",\n",
    "    \"temperature_2m\",\n",
    "    \"precipitation\",\n",
    "    \"cloud_cover\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"snowfall\", \n",
    "    \"rain\",  \n",
    "    \"is_work_free\",\n",
    "    \"is_red_day\",\n",
    "    \"is_day_before_holiday\",\n",
    "]\n",
    "\n",
    "DEFAULT_VEHICLE_FEATURES = {\n",
    "    \"max_speed\": 25.0,      # typical max speed (in m/s, i.e. 90 km/h)\n",
    "    \"n_positions\": 30,      # typical GPS points per trip window\n",
    "}\n",
    "\n",
    "forecast_dates = [today + timedelta(days=i) for i in range(1, forecast_days + 1)]\n",
    "hours = list(range(5, 24))\n",
    "forecast_times = [datetime.combine(d, datetime.min.time()).replace(hour=h)\n",
    "                  for d in forecast_dates for h in hours]\n",
    "\n",
    "weather_data = fetch_weather_all_hours(DEFAULT_LAT, DEFAULT_LON, forecast_days=forecast_days)\n",
    "time_list = weather_data.get(\"time\", [])\n",
    "weather_by_dt = {}\n",
    "\n",
    "for i, t in enumerate(time_list):\n",
    "    dt = datetime.strptime(t, \"%Y-%m-%dT%H:%M\")\n",
    "    weather_by_dt[dt] = {var: weather_data[var][i] for var in WEATHER_VARIABLES}\n",
    "\n",
    "weather_rows = []\n",
    "for dt in forecast_times:\n",
    "    row = {\"window_start\": dt}\n",
    "    row.update(weather_by_dt.get(dt, _default_weather()))\n",
    "    weather_rows.append(row)\n",
    "\n",
    "weather_df = pd.DataFrame(weather_rows)\n",
    "\n",
    "holiday_rows = []\n",
    "for d in forecast_dates:\n",
    "    holidays = get_holiday_features(datetime.combine(d, datetime.min.time()))\n",
    "    holiday_cleaned = {k: int(v) if v is not None else 0 for k, v in holidays.items()}\n",
    "    holiday_rows.append({\"_date\": d, **holiday_cleaned})\n",
    "holiday_df = pd.DataFrame(holiday_rows)\n",
    "\n",
    "# Feature table per trip\n",
    "forecast_rows = []\n",
    "for trip in static_df[\"trip_id\"].unique():\n",
    "    for dt in forecast_times:\n",
    "        row = {\n",
    "            \"window_start\": dt,\n",
    "            \"trip_id\": trip,\n",
    "            \"vehicle_id\": 0,\n",
    "            \"lat_mean\": DEFAULT_LAT,\n",
    "            \"lon_mean\": DEFAULT_LON,\n",
    "            \"hour\": dt.hour,\n",
    "            \"day_of_week\": dt.weekday(),\n",
    "            \"max_speed\": DEFAULT_VEHICLE_FEATURES[\"max_speed\"],\n",
    "            \"n_positions\": DEFAULT_VEHICLE_FEATURES[\"n_positions\"],\n",
    "        }\n",
    "        forecast_rows.append(row)\n",
    "\n",
    "forecast_features = pd.DataFrame(forecast_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0f3e821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149679\n",
      "Index(['window_start', 'trip_id', 'vehicle_id', 'lat_mean', 'lon_mean', 'hour',\n",
      "       'day_of_week', 'max_speed', 'n_positions'],\n",
      "      dtype='object')\n",
      "133\n",
      "Index(['window_start', 'temperature_2m', 'precipitation', 'cloud_cover',\n",
      "       'wind_speed_10m', 'rain', 'snowfall'],\n",
      "      dtype='object')\n",
      "7\n",
      "Index(['_date', 'is_work_free', 'is_red_day', 'is_day_before_holiday',\n",
      "       'holiday_name', 'day_of_week'],\n",
      "      dtype='object')\n",
      "datetime64[ns, UTC]\n",
      "datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "print(len(forecast_features))\n",
    "print(forecast_features.columns)\n",
    "\n",
    "print(len(weather_df))\n",
    "print(weather_df.columns)\n",
    "\n",
    "print(len(holiday_df))\n",
    "print(holiday_df.columns)\n",
    "\n",
    "forecast_features[\"_date\"] = forecast_features[\"window_start\"].dt.date\n",
    "forecast_features['_date'] = pd.to_datetime(forecast_features['_date'], utc=True)\n",
    "print(forecast_features['_date'].dtype)\n",
    "print(holiday_df['_date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "339d7c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'vehicle_id', 'lat_mean', 'lon_mean', 'hour',\n",
      "       'day_of_week', 'max_speed', 'n_positions', '_date', 'temperature_2m',\n",
      "       'precipitation', 'cloud_cover', 'wind_speed_10m', 'rain', 'snowfall'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(forecast_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550bd079",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_features = forecast_features.merge(weather_df, on=\"window_start\", how=\"left\")\n",
    "forecast_features[\"_date\"] = forecast_features[\"window_start\"].dt.date\n",
    "forecast_features['_date'] = pd.to_datetime(forecast_features['_date'], utc=True)\n",
    "forecast_features = forecast_features.merge(holiday_df, on=\"_date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cab4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'vehicle_id', 'lat_mean', 'lon_mean', 'hour',\n",
      "       'day_of_week_x', 'max_speed', 'n_positions', '_date',\n",
      "       'temperature_2m_y', 'precipitation_y', 'cloud_cover_y',\n",
      "       'wind_speed_10m_y', 'rain_y', 'snowfall_y', 'is_work_free',\n",
      "       'is_red_day', 'is_day_before_holiday', 'holiday_name', 'day_of_week_y'],\n",
      "      dtype='object')\n",
      "2149679\n"
     ]
    }
   ],
   "source": [
    "print(forecast_features.columns)\n",
    "print(len(forecast_features))\n",
    "\n",
    "forecast_features = forecast_features.drop(['precipitation_x', 'temperature_2m_x', 'cloud_cover_x', 'wind_speed_10m_x', 'rain_x',\n",
    "        'snowfall_x'], axis=1)\n",
    "\n",
    "forecast_features = forecast_features.rename(columns={\n",
    "    \"precipitation_y\": \"precipitation\",\n",
    "    \"temperature_2m_y\": \"temperature_2m\",\n",
    "    \"cloud_cover_y\": \"cloud_cover\",\n",
    "    \"wind_speed_10m_y\": \"wind_speed_10m\",\n",
    "    \"rain_y\": \"rain\",\n",
    "    \"snowfall_y\": \"snowfall\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5832b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_features = forecast_features.drop(['day_of_week_x'], axis=1)\n",
    "\n",
    "forecast_features = forecast_features.rename(columns={\n",
    "    \"day_of_week_y\": \"day_of_week\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e098e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'vehicle_id', 'lat_mean', 'lon_mean', 'hour',\n",
      "       'max_speed', 'n_positions', '_date', 'temperature_2m', 'precipitation',\n",
      "       'cloud_cover', 'wind_speed_10m', 'rain', 'snowfall', 'is_work_free',\n",
      "       'is_red_day', 'is_day_before_holiday', 'holiday_name', 'day_of_week'],\n",
      "      dtype='object')\n",
      "2149679\n"
     ]
    }
   ],
   "source": [
    "print(forecast_features.columns)\n",
    "print(len(forecast_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1260af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_forecast = forecast_features[FEATURE_ORDER]\n",
    "proba = model.predict_proba(X_forecast)\n",
    "\n",
    "forecast_features[\"predicted_occupancy_mode\"] = np.argmax(proba, axis=1)\n",
    "forecast_features[\"predicted_confidence\"] = proba.max(axis=1)\n",
    "forecast_features[\"predicted_proba\"] = proba.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "596af500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149679\n"
     ]
    }
   ],
   "source": [
    "print(len(forecast_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df378069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trip_id', 'window_start', 'vehicle_id', 'avg_speed', 'max_speed',\n",
      "       'n_positions', 'speed_std', 'lat_min', 'lat_max', 'lat_mean', 'lon_min',\n",
      "       'lon_max', 'lon_mean', 'bearing_min', 'bearing_max', 'occupancy_mode',\n",
      "       'date_x', 'hour', 'day_of_week', 'datetime_hour', '_date',\n",
      "       'temperature_2m', 'precipitation', 'cloud_cover', 'wind_speed_10m',\n",
      "       'snowfall', 'rain', 'date_y', 'is_work_free', 'is_red_day',\n",
      "       'is_day_before_holiday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hindcast_features = monitor_df[monitor_df[\"window_start\"] < today]\n",
    "\n",
    "print(hindcast_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5114e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcast_features = hindcast_features.drop(['date_x'], axis=1)\n",
    "\n",
    "hindcast_features = hindcast_features.rename(columns={\n",
    "    \"date_y\": \"date\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9d8308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trip_id', 'window_start', 'vehicle_id', 'avg_speed', 'max_speed',\n",
      "       'n_positions', 'speed_std', 'lat_min', 'lat_max', 'lat_mean', 'lon_min',\n",
      "       'lon_max', 'lon_mean', 'bearing_min', 'bearing_max', 'occupancy_mode',\n",
      "       'hour', 'day_of_week', 'datetime_hour', '_date', 'temperature_2m',\n",
      "       'precipitation', 'cloud_cover', 'wind_speed_10m', 'snowfall', 'rain',\n",
      "       'date', 'is_work_free', 'is_red_day', 'is_day_before_holiday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hindcast_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4a8bdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_features = VEHICLE_FEATURES + WEATHER_FEATURES + HOLIDAY_FEATURES\n",
    "missing = [c for c in required_features if c not in forecast_features.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing features from feature view: {missing}\")\n",
    "\n",
    "forecast_features[\"predicted_occupancy_mode\"] = model.predict(\n",
    "    forecast_features[required_features]\n",
    ")\n",
    "\n",
    "probas = model.predict_proba(forecast_features[required_features])\n",
    "\n",
    "forecast_features[\"predicted_confidence\"] = np.max(probas, axis=1)  # between 0 and 1\n",
    "\n",
    "forecast_out = forecast_features[[\n",
    "    \"window_start\",\n",
    "    \"trip_id\",\n",
    "    \"predicted_occupancy_mode\",\n",
    "    \"predicted_confidence\",\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f9c81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in HOLIDAY_FEATURES:\n",
    "    if col in hindcast_features.columns:\n",
    "        hindcast_features = hindcast_features.dropna(subset=HOLIDAY_FEATURES)\n",
    "        hindcast_features[col] = hindcast_features[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c921cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcast_features['trip_id'] = pd.to_numeric(hindcast_features['trip_id'], errors='coerce')\n",
    "hindcast_features = hindcast_features.dropna(subset=['trip_id'])\n",
    "\n",
    "hindcast_features['vehicle_id'] = pd.to_numeric(hindcast_features['vehicle_id'], errors='coerce')\n",
    "hindcast_features = hindcast_features.dropna(subset=['vehicle_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e76784a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcast_features[\"predicted_occupancy_mode\"] = model.predict(\n",
    "    hindcast_features[VEHICLE_FEATURES + WEATHER_FEATURES + HOLIDAY_FEATURES]\n",
    ")\n",
    "\n",
    "hindcast_out = hindcast_features[[\n",
    "    \"window_start\",\n",
    "    \"trip_id\",\n",
    "    \"occupancy_mode\",               # ground truth\n",
    "    \"predicted_occupancy_mode\"\n",
    "]].rename(columns={\n",
    "    \"occupancy_mode\": \"actual_occupancy_mode\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8521f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['window_start', 'trip_id', 'predicted_occupancy_mode',\n",
       "       'predicted_confidence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26fb70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'actual_occupancy_mode',\n",
      "       'predicted_occupancy_mode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hindcast_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'actual_occupancy_mode',\n",
      "       'predicted_occupancy_mode', 'route_id', 'route_short_name',\n",
      "       'route_long_name', 'route_desc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['route_id_x', 'route_short_name_x', 'route_long_name_x', 'route_desc_x'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(hindcast_out\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Keep only the _y columns (from static_df) and rename them back\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m hindcast_out \u001b[38;5;241m=\u001b[39m \u001b[43mhindcast_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroute_id_x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroute_short_name_x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                          \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroute_long_name_x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroute_desc_x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m hindcast_out \u001b[38;5;241m=\u001b[39m hindcast_out\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_id_y\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_short_name_y\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_short_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_long_name_y\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_long_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_desc_y\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroute_desc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m })\n",
      "File \u001b[0;32m~/miniconda3/envs/scalable-ml-env/lib/python3.10/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scalable-ml-env/lib/python3.10/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/scalable-ml-env/lib/python3.10/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/scalable-ml-env/lib/python3.10/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['route_id_x', 'route_short_name_x', 'route_long_name_x', 'route_desc_x'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Merge with static trip information for analytics\n",
    "\n",
    "forecast_out = forecast_out.merge(\n",
    "    static_df[\n",
    "        [\n",
    "            \"trip_id\",\n",
    "            \"route_id\",\n",
    "            \"route_short_name\",\n",
    "            \"route_long_name\",\n",
    "            \"route_desc\"\n",
    "        ]\n",
    "    ],\n",
    "    on=\"trip_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "hindcast_out = hindcast_out.merge(\n",
    "    static_df[\n",
    "        [\n",
    "            \"trip_id\",\n",
    "            \"route_id\",\n",
    "            \"route_short_name\",\n",
    "            \"route_long_name\",\n",
    "            \"route_desc\"\n",
    "        ]\n",
    "    ],\n",
    "    on=\"trip_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(hindcast_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b80bcb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'actual_occupancy_mode',\n",
      "       'predicted_occupancy_mode', 'route_id', 'route_short_name',\n",
      "       'route_long_name', 'route_desc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hindcast_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "437c2047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Results:\n",
      "    Accuracy:  0.7190\n",
      "    Precision: 0.6792 (weighted)\n",
      "    Recall:    0.7190 (weighted)\n",
      "    F1 Score:  0.6882 (weighted)\n",
      "    MAE:  0.2952\n"
     ]
    }
   ],
   "source": [
    "y_true = hindcast_out[\"actual_occupancy_mode\"]\n",
    "y_pred = hindcast_out[\"predicted_occupancy_mode\"]\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"\\n  Results:\")\n",
    "print(f\"    Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"    Precision: {precision:.4f} (weighted)\")\n",
    "print(f\"    Recall:    {recall:.4f} (weighted)\")\n",
    "print(f\"    F1 Score:  {f1_weighted:.4f} (weighted)\")\n",
    "print(f\"    MAE:  {mae:.4f}\")\n",
    "\n",
    "hindcast_out[\"precision\"] = precision\n",
    "hindcast_out[\"recall\"] = recall\n",
    "hindcast_out[\"accuracy\"] = accuracy\n",
    "hindcast_out[\"mae\"] = mae\n",
    "hindcast_out[\"f1_weighted\"] = f1_weighted\n",
    "hindcast_out[\"model_version\"] = model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f481756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_fg = fs.get_or_create_feature_group(\n",
    "    name=\"forecast_fg\",\n",
    "    version=1,\n",
    "    primary_key=[\"window_start\", \"trip_id\"],\n",
    "    description=\"Forward bus occupancy predictions\",\n",
    "    online_enabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ca5bc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_out = forecast_out.rename(columns={\n",
    "    \"route_id_y\": \"route_id\",\n",
    "    \"route_short_name_y\": \"route_short_name\",\n",
    "    \"route_long_name_y\": \"route_long_name\",\n",
    "    \"route_desc_y\": \"route_desc\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ddfa67e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5324256\n",
      "Index(['window_start', 'trip_id', 'predicted_occupancy_mode',\n",
      "       'predicted_confidence', 'route_id', 'route_short_name',\n",
      "       'route_long_name', 'route_desc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(forecast_out))\n",
    "print(forecast_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4fdfa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'predicted_occupancy_mode',\n",
      "       'predicted_confidence', 'route_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "forecast_out = forecast_out.drop(columns=[\"route_short_name\", \n",
    "                                          \"route_long_name\", \"route_desc\"])\n",
    "\n",
    "print(forecast_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "93c46bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5324256\n"
     ]
    }
   ],
   "source": [
    "print(len(forecast_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc436ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1271989/fs/1258587/fg/1908135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 5324256/5324256 | Elapsed Time: 01:24 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: forecast_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1271989/jobs/named/forecast_fg_1_offline_fg_materialization/executions\n",
      "2026-01-07 12:35:04,465 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2026-01-07 12:35:07,630 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-07 12:35:10,801 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-07 12:41:09,504 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-07 12:41:09,747 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-07 12:41:41,872 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('forecast_fg_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_fg.insert(\n",
    "    forecast_out,\n",
    "    write_options={\"wait_for_job\": True,\"overwrite\": True}   # only include latest forecast for that trip by overwriting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "56cb7e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['window_start', 'trip_id', 'actual_occupancy_mode',\n",
      "       'predicted_occupancy_mode', 'route_id', 'precision', 'recall',\n",
      "       'accuracy', 'mae', 'f1_weighted', 'model_version'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hindcast_out = hindcast_out.drop(columns=[\"route_long_name\", \"route_short_name\", \n",
    "                                          \"route_desc\"])\n",
    "\n",
    "print(hindcast_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "373b4b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14957087\n"
     ]
    }
   ],
   "source": [
    "print(len(hindcast_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc89abf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1271989/fs/1258587/fg/1893848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 14957087/14957087 | Elapsed Time: 05:55 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: monitor_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1271989/jobs/named/monitor_fg_1_offline_fg_materialization/executions\n",
      "2026-01-07 12:48:48,224 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-07 12:48:54,571 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-07 12:53:21,207 INFO: Waiting for execution to finish. Current state: FINISHED. Final status: SUCCEEDED\n",
      "2026-01-07 12:53:21,627 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-07 12:53:21,627 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('monitor_fg_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor_fg = fs.get_or_create_feature_group(\n",
    "    name=\"monitor_fg\",\n",
    "    version=1,\n",
    "    primary_key=[\"window_start\", \"trip_id\"],\n",
    "    description=\"Model monitoring and hindcast diagnostics\",\n",
    "    online_enabled=False\n",
    ")\n",
    "\n",
    "monitor_fg.insert(\n",
    "    hindcast_out,\n",
    "    write_options={\"wait_for_job\": True, \"overwrite\": False}   # append\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scalable-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
